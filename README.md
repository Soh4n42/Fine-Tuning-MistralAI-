# ğŸŸï¸ Sports Headline Generator using Mistral-7B + LoRA

This project fine-tunes [Mistral-7B-Instruct-v0.3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) using Low-Rank Adaptation (LoRA) to generate **catchy and realistic sports news headlines** from a simple instruction prompt.
The main aim of this project is to understand about the steps involved in fine tuning a llm models such as choosing a model, bits and bytes configuration, loading the model, tokenization, lora weight adaptation, training the model and inferencing to check the results
---

## ğŸ“¦ Project Structure
.
â”œâ”€â”€ data_collection/   # Scripts and data for scraping & preparing the dataset

â”‚   â”œâ”€â”€ scrape.py                   # Script to scrape sports news headlines from the web
â”‚   â”œâ”€â”€ prompt_formatting.py        # Script to convert scraped data into prompt-response format
â”‚   â”œâ”€â”€ train.txt                   # Raw headlines (optional intermediate file)
â”‚   â”œâ”€â”€ train.json                  # Final training dataset in prompt-response JSON format

â”œâ”€â”€ ft_mistral.ipynb               # Notebook to fine-tune Mistral-7B using LoRA (PEFT + TRL)

â”œâ”€â”€ README.md                      # Project documentation with instructions and usage

â”œâ”€â”€ pyproject.toml                 # Python dependencies and project metadata

â”œâ”€â”€ .gitignore                     # Git ignored files (e.g., checkpoints, logs, cache)



---

## ğŸ“Š Dataset

You create a custom dataset of sports news headlines extracted from sources like:

- Espn
- Fox Sports
- BBC
- CNN

### ğŸ”§ Format: `train.json`

```json
{"prompt": "Generate a sports news headline.", "response": "Spain begin Euro 2025 campaign by thrashing Portugal"}
{"prompt": "Generate a sports news headline.", "response": "Can Raducanu bridge gap to world's best Sabalenka?"}
```


ğŸ§  Model & Training
âœ… Base model: mistralai/Mistral-7B-Instruct-v0.1

âœ… Quantization: 4-bit using bitsandbytes

âœ… PEFT: LoRA for memory-efficient fine-tuning

âœ… Frameworks: transformers, trl, peft, datasets

ğŸ‹ï¸ Training Objective
To teach the model to generate well-formed, realistic headlines from a fixed instruction prompt.


### ğŸ” Inference Example

```python
from transformers import pipeline

generator = pipeline("text-generation", model="your-model", tokenizer="your-tokenizer")

prompt = "Generate a sports news headline."
output = generator(prompt, max_new_tokens=30)
print(output[0]["generated_text"])

